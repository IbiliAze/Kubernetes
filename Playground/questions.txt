x//// 1). Create a pod with environment variables as var1=value1. Check the environment variable in pod

Answer:
kubectl run nginx --image=nginx --restart=Never --env=var1=value1
kubectl exec -it nginx -sh -c 'echo $var1'
or
kubectl exec -it nginx -- /bin/sh -c 'echo $var1'


x/// 2). Create a pod that echo hello world and then exists. Have the pod deleted automatically when its completed

Answer:
kubectl run busybox --image=busybox -it --rm --restart=Never --command -- /bin/sh -c 'echo hello world'
or
kubectl run busybox --image=busybox -it --rm --restart=Never -- /bin/sh -c 'echo hello world'
kubectl get pods


xx/// 4). List the nginx pod with custom columns POD_NAME and POD_STATUS

Answer:
kubectl get pods -o yaml #get the yaml output to parse
kubectl get pods -o custom-columns="POD_NAME:metadata.name, POD_STATUS:.status.conditions[-1].type"
or
kubectl get pods -o custom-columns=POD_NAME:.metadata.name,POD_STATUS:.status.conditions[-1].type


//// 5). Create a pod as follows:
 Name: mongo
 Using Image: mongo
 In a new Kubernetes namespace named: my-website

Answer:
kubectl create ns my-website
kubectl run --image=mongo -n my-website
kubectl get pods -n my-website


x//// 7). List pod logs named "frontend" and search for the pattern "started" and write it to a file "/opt/error-logs"

Answer:
kubectl logs frontend | grep -i started > /opt/error-logs


xx///x 8). List all persistent volumes sorted by capacity, saving the full kubectl output to
/opt/KUCC00102/volume_list. Use kubectl's own functionality for sorting the output, and do not manipulate it any further

Answer:
kubectl get pv -o yaml
kubectl get pv --sort-by=.spec.capacity.storage > /opt/KUCC00102/volume_list


//// 9). Create a namespace called 'development' and a pod with image nginx called nginx on this namespace.

Answer:
kubectl create ns development
kubectl run nginx --image=nginx --restart=Never -n=development


x//// 10). Create a pod as follows:
 Name: non-persistent-redis
 container Image: redis
 Volume with name: cache-control
 Mount path: /data/redis
The pod should launch in the staging namespace and the volume must not be persistent.

Answer:
kubectl run non-persistent-redis --image=redis -n staging --dry-run=client -o yaml > pod.yaml
vim pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: non-persistent-redis
  namespace: staging
spec:
  containers:
  - name: redis
    image: redis
    volumeMounts:
    - name: cache-control
      mountPath: /data/redis
  volumes:
  - name: cache-control
    emptyDir: {}
kubectl create -f pod.yaml
kubectl get pods -n staging


x//x 11). Ensure a single instance of pod nginx is running on each node of the Kubernetes cluster where nginx also represents the 
 Image name which has to be used. Do not override any taints currently in place.
 Use DaemonSet to complete this task and use ds-kusc00201 as DaemonSet name.

Answer:
vim ds.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ds-kusc00201
spec:
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  template:
    metadata:
      labels:
        name: fluentd-elasticsearch
    spec:
      containers:
      - image: nginx
        name: nginx
kubectl create -f ds.yaml


///// 12). Get list of all pods in all namespaces and write it to file "/opt/pods-list.yaml"

Answer:
kubectl get pods --all-namespaces > /opt/pods-list.yaml


//// 13). Get list of all the pods showing name and namespace with a jsonpath expression.

Answer:
kubectl get pods --all-namespaces -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.namespace}{"\n"}{end}'


14). Use context: kubectl config use-context k8s-c2-AC

The cluster admin asked you to find out the following information about etcd running on cluster2-master1:

Server private key location
Server certificate expiration date
Is client certificate authentication enabled
Write these information into /opt/course/p1/etcd-info.txt

Finally you're asked to save an etcd snapshot at /etc/etcd-snapshot.db on cluster2-master1 and display its status.

Answer:
kubectl config use-context k8s-c2-AC
kubectl get nodes
ssh cluster2-master1
kubectl -n kube-system get pod
find /etc/kubernetes/manifests/
vim /etc/kubernetes/manifests/etcd.yaml
openssl x509  -noout -text -in /etc/kubernetes/pki/etcd/server.crt | grep Validity -A2
echo "Server private key location: /etc/kubernetes/pki/etcd/server.key
Server certificate expiration date: Sep  4 15:28:39 2021 GMT
Is client certificate authentication enabled: yes" > /opt/course/p1/etcd-info.txt
ETCDCTL_API=3 etcdctl snapshot save /etc/etcd-snapshot.db
ETCDCTL_API=3 etcdctl snapshot save /etc/etcd-snapshot.db \
  --cacert /etc/kubernetes/pki/etcd/ca.crt \
  --cert /etc/kubernetes/pki/etcd/server.crt \
  --key /etc/kubernetes/pki/etcd/server.key
ETCDCTL_API=3 etcdctl snapshot status /etc/etcd-snapshot.db


x//// 15). Create 2 nginx image pods in which one of them is labelled with env=prod and another one labelled with env=dev and verify the same.

Answer:
kubectl run --image=nginx --labels=env=prod nginx-pod --dry-run=client -o yaml
kubectl run --image=nginx --labels=env=prod nginx-pod
kubectl run --image=nginx --labels=env=dev nginx-pod
kubectl get po --show-labels
kubectl get po -l env=prod
kubectl get po -l env=dev


/x 16). Print pod name and start time to '/opt/pod-status' file

Answer:
kubectl get pods nginx-pod -o yaml
k get pod -o=jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.startTime}{"\n"}{end}'
or
k get pod -o=jsonpath="{range .items[*]}{.metadata.name}{'\t'}{.status.startTime}{'\n'}{end}"


/x/// 17). Create a busybox pod and add 'sleep 3600' command

Answer:
kubectl run busybox --image=busybox --restart=Never -- /bin/sh -c 'sleep 3600'


//// 18). List 'nginx-dev' and 'nginx-prod' pod and delete those pods

Answer:
kubectl get pods -o wide
kubectl delete po nginx-dev
kubectl delete po nginx-prod


xx///x 19). Create a redis pod and mount "redis-config" as "redis.conf" inside redis container, name the config volume as
 "redis-volume" redis-config path - /opt/redis-config

Answer:
k create configmap redis-config --from-file redis.conf
k run redis --image=redis --dry-run=client -o yaml > redis.yaml

vim redis.yaml
apiVersion: v1
kind: Pod
metadata:
  name: redis
spec:
  containers:
  - image: redis
    name: redis
    volumeMounts:
    - name: redis-volume
      mountPath: /opt/redis-config
  volumes:
  - name: redis-volume
    configMap:
      name: redis-config

kubectl  apply -f redis.yaml


xx/x 20). Create a deployment as follows:
 Name: nginx-random
 Exposed via a service: nginx-random
 Ensure that the service & pod are accessible via their respective DNS records
 The container(s) within any pod(s) running as a part of this deployment should use the nginx Image
Next, use the utilitynslookup to lookup the DNS records of the service & pod and write the output to
/opt/KUNW00601/service.dns and /opt/KUNW00601/pod.dns respectively.

Answer:
kubectl create deployment nginx-random --image=nginx
kubectl expose deployment nginx-random --name=nginx-random --port=80 --target-port=80
kubectl run busybox --image=busybox --dry-run=client -o yaml --command sleep 3600
kubectl get pods -o wide | grep nginx-random
kubectl exec -it busybox -- nslookup kubernetes.default
kubectl exec -it busybox -- nslookup nginx-random
kubectl exec -it busybox -- nslookup nginx-random > /opt/KUNW00601/service.dns
kubectl exec -it busybox -- nslookup 10-44-1-5.default.pod.cluster.local
kubectl exec -it busybox -- nslookup 10-44-1-5.default.pod.cluster.local > /opt/KUNW00601/pod.dns


// 21). Given a partially-functioning Kubernetes cluster, identify symptoms of failure on the cluster.
Determine the node, the failing service, and take actions to bring upthe failed service and restore the health of the cluster. 
Ensure that anychanges are made permanently.
You can ssh to the relevant Inodes (bk8s-master-0orbk8s-node-0) using:
[student@node-1] $ ssh <nodename>
You can assume elevated privileges on any node in the cluster with the following command:
[student@nodename] $ | sudo -i

Answer:
kubectl config use-context bk8s
ssh bk8-master-0
sudo -i
journalctl -u kubelet
cd /var/log; more syslog | tail 120 | grep kubelet; cd ../..
vim /var/lib/kubelet/config.yaml
systemctl restart kubelet
systemctl enable kubelet
kubectl get nodes
exit
exit


/////// 22). Monitor the logs of pod foo and:
 Extract log lines corresponding to error unable-to-access-website
 Write them to /opt/KULM00201/foo

Answer:
kubectl logs foo | grep -i unable-to-access-website
kubectl logs foo | grep -i unable-to-access-website > /opt/KULM00201/foo


x///x 23). Create a deployment as follows:
 Name: nginx-app
 Using container nginx with version 1.11.10-alpine
 The deployment should contain 3 replicas
 Next, deploy the application with new version 1.11.13-alpine, by performing

Answer:
kubectl create deployment nginx-app --image=nginx:1.11.10-alpine --replicas=3 --dry-run=client -o yaml > app.yaml
kubectl create -f app.yaml
kubectl set image deployment nginx-app nginx=nginx:1.11.13-alpine --record
kubectl rollout undo deployment nginx-app
kubectl rollout history deployment nginx-app
kubectl rollout status deployment nginx-app


xx///// 24). Set the node named ek8s-node-1 as unavailable and reschedule all the pods running on it.

Answer:
kubectl config use-context ek8s
kubectl get nodes
kubectl drain ek8s-node-1 --ignore-daemonsets --delete-local-data --force
or
kubectl drain ek8s-node-1 --ignore-daemonsets --delete-emptydir-data --force


/x///// 25). From the pod label name=cpu-utilizer, find pods running high CPU workloads and
write the name of the pod consuming most CPU to the file /opt/KUTR00102/KUTR00102.txt (which already exists).

Answer:
kubectl top pods -l name=cpu-utilizer
vim /opt/KUTR00102/KUTR00102.txt #add the top pod name


////// 26). Check the Image version of nginx-dev pod using jsonpath

Answer:
k get pod nginx-dev -o jsonpath='{.spec.containers[].image}{"\n"}'


/////// 27). List all the pods sorted by name

Answer:
kubectl get pods --sort-by='{.metadata.name}'


///// 28). Create a pod that having 3 containers in it

Answer:
k run multi-container --image=nginx --dry-run=client -o yaml > multi-container.yaml
vim multi-container.yaml
# append "- image: redis
name: redis-container
- image: consul
name: consul-cont" to containers
kubectl create -f multi-container.yaml


////// 29). Schedule a pod as follows:
 Name: nginx-kusc00101
 Image: nginx
 Node selector: disk=ssd

Answer:
kubectl run nginx-kusc00101 --image=nginx --dry-run=client -o yaml > nginx-kusc00101.yaml
vim nginx-kusc00101.yaml
append "nodeSelector:
    disk: ssd" to spec
kubectl apply -f nginx-kusc00101.yaml
kubectl get pods

as such: 
apiVersion: v1
kind: Pod
metadata:
  name: nginx-kusc00101
spec:
  containers:
  - image: nginx
    name: nginx-kusc00101
  nodeSelector:
    disk: ssd


xx//xx/x 30). Create a persistent volume with name app-data, of capacity 2Gi and access mode ReadWriteMany. 
 The type of volume is hostPath and its location is /srv/app-data.

Answer:
echo "apiVersion: v1
kind: PersistentVolume
metadata:
  name: app-data
spec:
  capacity:
    storage: 2Gi
  accessModes:
  - ReadWriteMany
  hostPath:
    path: /srv/app-data
  storageClassName: shared" > pv.yaml
kubectl create -f pv.yaml
kubectl get pv


//// 31). Create a busybox pod that runs the command "env" and save the output to "envpod" file

Answer:
kubectl run busybox --image=busybox -it --rm --restart=Never -- /bin/sh -c 'env > envpod.yaml'
or
kubectl run busybox --image=busybox --rm -it --restart=Never -- env > envpod.yaml


/x 32). A Kubernetes worker node, named wk8s-node-0is in state NotReady.
Investigate why this is the case, and perform any appropriate steps to bring the node to
a Readystate, ensuring that any changes are made permanent.
You can ssh to the failednode using:
[student@node-1] $ ssh hWk8s-node-0
You can assume elevated privileges on the node with th efollowing command:
[student@w8ks-node-0] $ sudo ?Ci

Answer:
k get nodes
ssh hWk8s-node-0
sudo -i
journalctl -u kubelet
cd /var/log; more syslog | tail 120 | grep kubelet; cd ../..
vim /var/lib/kubelet/config.yaml
systemctl restart kubelet
systemctl enable kubelet
exit
exit
kubectl get nodes


xxx///// 32). Create a snapshot of the etcd instance running at https://127.0.0.1:2379, saving the snapshot to the file path /srv/data/etcd-snapshot.db.
The following TLS certificates/key are supplied for connecting to the server with etcdctl:
 CA certificate: /opt/KUCM00302/ca.crt
 Client certificate: /opt/KUCM00302/etcd-client.crt
 Client key: /opt/KUCM00302/etcd-client.key

Answer: 
ETCDCTL_API=3 etcdctl snapshot save /srv/data/etcd-snapshot.db \
 --endpoints=https://127.0.0.1:2379 \
 --cacert=/opt/KUCM00302/ca.crt \
 --cert=/opt/KUCM00302/etcd-client.crt \
 --key=/opt/KUCM00302/etcd-client.key
ETCDCTL_API=3 etcdctl snapshot status /srv/data/etcd-snapshot.db


/////// 33). Scale the deployment "webserver" to 6 pods

Answer:
k get deployments
k scale deploy webserver --replicas=6
k get pods


? 34). Check to see how many worker nodes are ready (not including nodes tainted NoSchedule) 
and write the number to /opt/KUCC00104/kucc00104.txt


x//x//x/ 35). Add a new node

Answer:
ssh master-node
sudo su -
kubeadm token generate #or below command
kubeadm token create $(kubeadm token generate) --ttl 2hr --print-join-command
exit
exit
ssh worker node
sudo su -
#paste the output from the command above
exit
exit


xxx////// 36) Fix kubelet on master node

Answer:
sudo su -
swapoff -a && sed -i '/swap / s/^/#/' /etc/fstab

systemctl status firewalld
systemctl stop firewalld
systemctl disable firewalld


/x////x 37). Check if metrics server is responding

Answer:
k get --raw /apis/metrics.k8s.io/


x/xx// 38). Get metrics info for busybox pod containers

Answer:
k top pods busybox --containers


x/xx 39). Run a pod with liveness probe with the default HTTP health checker

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: pod
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
kubectl get ep


x///// 40) Run a pod with a readyness probe

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: pod
    readynessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5
kubectl get ep


////// 41). Check container logs

Answer:
cd /var/log/containers


/////// 42). Get logs from pod pod1, container2

Answer:
kubectl logs pod1 -c container2


x/////// 43). Get logs from previously ran pod1 and all containers in it

Answer:
kubectl logs -p pod1 --all-containers=true


///////// 44). Run a pod with a service account "my-sa"

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  serviceAccountName: my-sa
  containers:
  - image: nginx
    name: pod


45). Add a new user "user1"

Answer:
# on the master node
kubectl config set-credentials user1 --username=user1 --password=pass1
kubectl create clusterrolebinding anon-users --clusterrole=cluster-admin --user=system:anonymous
scp /etc/kubernetes/pki/ca.crt ibili@<IP of user1's machine>:~/
kubectl config view # note the server IP

# user1's machine
kubectl config set-cluster kubernetes --server=<IP of master server> --certificate-authority=ca.crt --embed-certs=true
kubectl config set-credentials user1 --username=user1 --password=pass1
kubectl config set-context kubernetes --cluster=kubernetes --user=user1 --namespace=default
kubectl config use-context kubernetes
kubectl get nodes


x////// 46). Start a busybox shell with the container name busybox

Answer:
k exec busybox -c busybox -it -- /bin/sh
or
k exec busybox -c busybox --stdin --tty -- /bin/sh


xx/ 47). Create a storage class with allowed volume expansion

Answer:
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: localdisk
provisioner: kubernetes.io/no-provisioner
allowVolumeExpansion: true


xx/x 48) Create a PV with reclaim policies

Answer:
apiVersion: v1
kind: PersistentVolume
metadata:
  name: app-data
spec:
  capacity:
    storage: 2Gi
  accessModes:
  - ReadWriteMany
  hostPath:
    path: /srv/app-data
  storageClassName: shared
  persistentVolumeReclaimPolicy: Retain, Delete, Recycle


xx///// 49). Create a pod which uses a volume from PVC "claim1"

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: non-persistent-redis
  namespace: staging
spec:
  containers:
  - name: redis
    image: redis
    volumeMounts:
    - name: myvol
      mountPath: /data
  volumes:
  - name: myvol
    persistentVolumeClaim:
      claimName: claim1


xxxxxx/ 50.1). Create a network policy with namespace selector label ns:myns, on TCP:80

Answer:
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: mynp
spec:
  podSelector:
    matchLabels:
      app: nginx
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          team: np-test
    ports:
    - protocol: TCP
      port: 80


/ 50.2). Create a network policy for pod with label app:nginx

Answer:
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: mynp
spec:
  podSelector:
    matchLabels:
      app: nginx
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: nginx


/ 50.3). Create a network policy for network 172.16.0.0, except 172.16.0.2

Answer:
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: mynp
spec:
  podSelector:
    matchLabels:
      app: nginx
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.16.0.0/26
        except:
        - 172.16.0.2


x//////// 51). Go to nginx-app deployment revision 2

Answer:
kubectl rollout undo deployment nginx-app --to-revision=2
kubectl rollout status deployment nginx-app


///////// 52). Schedule a pod on node "node-1"

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: nginx-kusc00101
spec:
  containers:
  - image: nginx
    name: nginx-kusc00101
  nodeName: node-1


//////// 53). Add a label "env:prod" to "node-1"

Answer:
kubectl label nodes node-1 env=prod
kubectl get nodes --show-labels


/x//// 54). create a pod with env from configmap "mycm", with key "NODE_ENV"

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: nginx-kusc00101
spec:
  containers:
  - image: nginx
    name: nginx-kusc00101
    env:
    - name: NODE_ENV
      valueFrom:
        configMapKeyRef: 
          name: mycm
          key: NODE_ENV


////// 55). create a pod with "mysec" as secret volume to /data

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: nginx-kusc00101
spec:
  containers:
  - image: nginx
    name: nginx-kusc00101
    volumeMounts:
    - name: mysec
      mountPath: /data
  volumes:
  - name: mysec
    secret:
      secretName: mysec


/////x 56). Schedule a pod with 250m of CPU and 128Mi of memory

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: nginx
    resources:
      requests:
        cpu: 250m
        memory: 128Mi


////x 57). Create a pod that will run a command "echo hello world", if failed the pod will be terminated

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: pod
    livenessProbe:
      exec:
        command: ["echo hello world"]
      initialDelaySeconds: 5
      periodSeconds: 5

  
xxxx 58). Create a pod with a startup probe

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: pod
    startupProbe:
      httpGet:
        path: /
        port: 80
      failureThreshold: 30
      periodSeconds: 10
kubectl get ep


/////// 59). Create an init container, that sleeps for 30 seconds

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: pod
  initContainers:
  - name: delay
    image: busybox
    command: ['sleep', '30']


////// 60). Create a static pod at worker-node1

Answer:
ssh worker-node1
sudo echo "apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: nginx" > /etc/kubernetes/manifests/my-sp.yml
sudo systemctl restart kubelet


////// 61). Drain node "node-1" then uncordon it

Answer:
kubectl drain node-1 --ignore-daemonsets --delete-local-data --force
or
kubectl drain node-1 --ignore-daemonsets --delete-emptydir-data --force
kubectl uncordon node-1


xxx 62). Upgrade the master node

Answer:
ssh master-1
sudo apt update && \
  sudo apt install -y --allow-change-held-packages kubeadm=1.20
kubectl drain master-1 --ignore-daemonsets
sudo kubeadm upgrade plan
sudo kubeadm upgrade apply v1.20
kubectl uncordon master-1

sudo apt update && \
  sudo apt install -y --allow-change-held-packages kubelet=1.20 kubectl=1.20
sudo systemctl daemon-reload
sudo systemctl restart kubelet

kubectl get nodes


xxx 63). Upgrade the worker node "node-1"

Answer:
ssh node-1
sudo apt update && \
  sudo apt install -y --allow-change-held-packages kubeadm=1.20
exit

ssh master-1
kubectl drain node-1 --ignore-daemonsets --force
exit

ssh node-1
sudo kubeadm upgrade node
sudo apt update && \
  sudo apt install -y --allow-change-held-packages kubelet=1.20 kubectl=1.20
sudo systemctl daemon-reload
sudo systemctl restart kubelet
exit

ssh master-1
kubectl uncordon node-1
exit


//////// 64). Restore from a snapshot at /data

Answer:
ETCDCTL_API=3 etcdctl snapshot restore /data


x//// 65). Create a role that allows to view pods and pod logs and bind to user "dev"

Answer:
k create role reader --verb=get,list,watch --resource=pods,pods/logs
k create rolebinding  myrb --role=myrole --user=dev

x//x/ 66). Create a role binding that uses serviceAccountName "mysa" as a subject

Answer:
k create rolebinding  myrb --role=myrole --serviceaccount=default:mysa


/////x 67). Create a pod with a TCP liveness probe on port 5000

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: pod
    livenessProbe:
      tcpSocket:
        port: 5000
      initialDelaySeconds: 5
      periodSeconds: 5


//// 68). Taint a node with label env=dev with "NoSchedule" effect

Answer:
k taint node node1 env=dev:NoSchedule


//// 69). Add a toleration to pod1 with env=prod and "NoSchedule" effect

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - image: nginx
    name: pod
  tolerations:
  - key: env
    value: prod
    operator: Equal
    effect: NoSchedule


70). Create a new user

Answer:
scp root@master-node:/etc/kubernetes/pki/ca.{crt,key} .

openssl genrsa -out bob.key 2048
openssl req -new -key bob.key -out bob.csr -subj "/CN=bob/O=finance"
openssl x509 \
  -req -in bob.csr -CA ca.cert -CAkey ca.key -CAcreateserial -out bob.crt -days 365

kubectl create ns newusers
kubectl create role newusers \
  --verb get,list,watch,create,update,patch,delete \
  --resource deployments,replicasets,pods \
  -n newusers
kubectl create rolebinding newusers \
  --role newusers \
  --user bob \
  -n newusers

kubectl config view
kubectl --kubeconfig bob.kubeconfig config set-cluster kubernetes \ 
  --server https://10.1.1.1:6443 \
  --certificate-authority ca.crt
kubectl --kubeconfig bob.kubeconfig config set-credentials bob \
  --client-certificate bob.crt \
  --client-key bob.key
kubectl --kubeconfig bob.kubeconfig config set-context bob-kube \
  --cluster kubernetes \
  --namespace newusers \
  --user bob
kubectl --kubeconfig bob.kubeconfig clusterinfo
kubectl --kubeconfig bob.kubeconfig get pods \
  --namespace newusers

cp bob.kubeconfig ~/.kube/config


/x 71). Create and configure a service "front-end-service" access through a NodePort that routes
 traffic to "front-end" pod

Answer:
kubectl expose po front-end --name front-end-service --port 80 --target-port 80 --type NodePort


// 72). Create an nginx pod running on port 80

Answer:
kubectl run mynginx --image=nginx --restart=Never --port=80


// 73). Create a configmap with literal value appname=myapp

Answer:
k create cm mycm --from-literal=appname=myapp


x 74). For this item, you will have to ssh to the nodes ik8s-master-0 and ik8s-node-0 and complete all tasks on these nodes. 
Ensure that you return to the base node (hostname:node-1) when you have completed this item.
Context
As an administrator of a small development team, you have been asked to set up a Kubernetes cluster to test the viability of a new application.
Task
You must use kubeadm to perform this task. Any kubeadm invocations will require the use of the --ignore-preflight-errors=all option.
 Configure the node ik8s-master-O as a masternode. .
 Join the node ik8s-node-o to the cluster.

Answer:
ssh ik8s-master-0
kubeadm init --pod-network-cidr=10.244.0.0/16 --ignore-preflight-errors=all
mkdir -p $HOME/.kube/config
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config
kubectl apply -f https://docs.projectcalico.org/v3.14/manifests/calico.yaml
logout

ssh ik8s-node-0
<paste the join command>


/// 75). Create an nginx pod and list the pod with different levels of verbosity

Answer:
kubectl run myimage --image=nginx --restart=Never
kubectl get po --v 1
kubectl get po --v 3
kubectl get po --v 5
kubectl get po --v 7
kubectl get po --v 9


/x 76). Check that the pod "nginx-pod" is responding on ports 5000 and 6000. Do this using port-forwarding

Answer:
k port-forward pod/nginx-pod 5000 6000

ssh another-node
curl --head <ip of nginx-pod:5000>
curl --head <ip of nginx-pod:6000>


/x 77). Check that the pod "nginx-pod" is responding on port 8080 locally and 80 on the pod. Do this using port-forwarding

Answer:
k port-forward pod/nginx-pod 8080:80

ssh another-node
curl --head <ip of nginx-pod:8080>


// 78). Create a pod with a termination message path to /var/termination.log

Answer:
apiVersion: v1
kind: Pod
metadata:
  name: non-persistent-redis
  namespace: staging
spec:
  containers:
  - name: redis
    image: redis
    terminationMessagePath: /var/termination.log


79). Create a custom cert for a pod

Answer:
cat <<EOF | cfssl genkey - | cfssljson -bare server
{
  "hosts": [
    "my-svc.my-namespace.svc.cluster.local",
    "my-pod.my-namespace.svc.cluster.local",
    "172.168.0.24",
    "10.0.32.2"
  ],
  "CN": "my-pod.my-namespace.svc.cluster.local",
  "key": {
    "algo": "ecdsa",
    "size": 256
  }
}
EOF

cat << EOF | kubectl create -f - apiVersion: certificates.k8s.io/v1beta1
kind: CertificateSigningRequest
metadata:
  name: pod-csr.web
spec:
  groups:
  - system:authenticated
  request: $(cat server.csr | base64 | tr -f '\n')
  usages:
  - digital signature
  - key encipherment
  - server auth
EOF

k get csr pod-csr.web -o jsonpath='{.status.certificate}' | base64 --decode > server.crt


x 80). Modify the default serviceaccount to use a custom DPR secret

Answer:
k create secret docker-registry mypr \
  --docker-server=https://example.com \
  --docker-username=ibi \
  --docker-password=cisco123 \
  --docker-email=ibi@example.com
k patch sa default -p '{"imagePullSecrets": [{"name": "mypr"}]}'
k get sa default -o yaml


x 81). Create a pod container with a guest user context

Answer:
cat << EOF | kubectl create -f - apiVersion: v1
kind: Pod
metadata:
  name: mypo
  namespace: staging
spec:
  containers:
  - name: redis
    image: redis
    securityContext:
      runAsUser: 405
EOF
k exec mypo id 


x 82). Create a pod container with a non-root user context

Answer:
cat << EOF | kubectl create -f - apiVersion: v1
kind: Pod
metadata:
  name: mypo
  namespace: staging
spec:
  containers:
  - name: redis
    image: redis
    securityContext:
      runAsNonRoot: true
EOF
k exec mypo id 


x 83). Create a pod container with a privileged mode

Answer:
cat << EOF | kubectl create -f - apiVersion: v1
kind: Pod
metadata:
  name: myprivpo
  namespace: staging
spec:
  containers:
  - name: redis
    image: redis
    securityContext:
      privileged: true
EOF
k exec mypo ls /dev # should show less
k exec myprivpo ls /dev


x 84). Create a pod container with "SYS_TIME" and "NET_ADMIN" capabilities, and no "CHOWN" capability

Answer:
cat << EOF | kubectl create -f - apiVersion: v1
kind: Pod
metadata:
  name: myprivpo
  namespace: staging
spec:
  containers:
  - name: redis
    image: redis
    securityContext:
       capabilities:
         add:
         - SYS_TIME
         - NET_ADMIN
         drop:
         - CHOWN
EOF
k exec myprivpo ls /dev


x 85). Create a pod container with readyonly user

Answer:
cat << EOF | kubectl create -f - apiVersion: v1
kind: Pod
metadata:
  name: myprivpo
  namespace: staging
spec:
  containers:
  - name: redis
    image: redis
    securityContext:
      readOnlyRootFileSystem: true
EOF
k exec myprivpo touch file #should receive error